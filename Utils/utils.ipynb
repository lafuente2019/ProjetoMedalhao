{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9283f40e-69de-4ec2-99d0-40e81aa75c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e481c53-ee7c-481c-a762-a870d40adba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def merge_delta_table(df_join, tabela_destino):\n",
    "    \"\"\"\n",
    "    Realiza MERGE (upsert) de um DataFrame em uma tabela Delta Lake.\n",
    "\n",
    "    Regras de chaves:\n",
    "    -----------------\n",
    "    - Para 'workspace.bronze_etl.ipca' ou 'workspace.bronze_etl.boi_gordo': usa as colunas 'data', 'valor'\n",
    "    - Para demais tabelas: usa as colunas 'data', 'ipca', 'boi_gordo'\n",
    "\n",
    "    Par√¢metros:\n",
    "    -----------\n",
    "    df_join : DataFrame\n",
    "        DataFrame com os dados a serem inseridos/atualizados.\n",
    "    tabela_destino : str\n",
    "        Nome completo da tabela Delta (ex: 'workspace.bronze_etl.ipca' ou 'workspace.gold_etl.insights').\n",
    "\n",
    "    Retorno:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    if df_join is not None and df_join.limit(1).count() > 0:\n",
    "        total = df_join.count()\n",
    "        print(f\"‚úÖ Total de registros carregados: {total}\")\n",
    "\n",
    "        if spark.catalog.tableExists(tabela_destino):\n",
    "            print(f\"üì¶ Tabela {tabela_destino} j√° existe ‚Äî atualizando dados...\")\n",
    "\n",
    "            delta_table = DeltaTable.forName(spark, tabela_destino)\n",
    "\n",
    "            # üîë Define a condi√ß√£o de merge conforme a tabela\n",
    "            if tabela_destino in [\n",
    "                \"workspace.bronze_etl.ipca\",\n",
    "                \"workspace.bronze_etl.boi_gordo\"\n",
    "            ]:\n",
    "                condicao_merge = \"t.data = s.data AND t.valor = s.valor\"\n",
    "                print(\"üîë Usando chaves: data, valor\")\n",
    "            else:\n",
    "                condicao_merge = (\n",
    "                    \"t.data = s.data \"\n",
    "                    \"AND t.ipca = s.ipca \"\n",
    "                    \"AND t.boi_gordo = s.boi_gordo\"\n",
    "                )\n",
    "                print(\"üîë Usando chaves: data, ipca, boi_gordo\")\n",
    "\n",
    "            # üöÄ Executa o MERGE\n",
    "            (\n",
    "                delta_table.alias(\"t\")\n",
    "                .merge(\n",
    "                    df_join.alias(\"s\"),\n",
    "                    condicao_merge\n",
    "                )\n",
    "                .whenMatchedUpdateAll()\n",
    "                .whenNotMatchedInsertAll()\n",
    "                .execute()\n",
    "            )\n",
    "\n",
    "            print(f\"‚úÖ MERGE conclu√≠do com sucesso em {tabela_destino}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"üÜï Tabela {tabela_destino} n√£o existe ‚Äî criando nova tabela...\")\n",
    "\n",
    "            df_join.write \\\n",
    "                .format(\"delta\") \\\n",
    "                .partitionBy(\"data\") \\\n",
    "                .mode(\"append\") \\\n",
    "                .option(\"overwriteSchema\", \"true\") \\\n",
    "                .saveAsTable(tabela_destino)\n",
    "\n",
    "            print(f\"‚úÖ Tabela {tabela_destino} criada e dados inseridos com sucesso.\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum dado para atualizar.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
