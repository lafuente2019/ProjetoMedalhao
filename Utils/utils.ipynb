{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9283f40e-69de-4ec2-99d0-40e81aa75c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15e46f4b-cbb8-4a3e-94b7-779e8a09891f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e481c53-ee7c-481c-a762-a870d40adba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_merge_condition(tabela_destino: str) -> str:\n",
    "    \"\"\"\n",
    "    Retorna a condi√ß√£o de MERGE (string SQL) de acordo com a tabela de destino.\n",
    "    Essa fun√ß√£o √© pura (n√£o depende de Spark) e √© f√°cil de testar.\n",
    "    \"\"\"\n",
    "    if tabela_destino in [\n",
    "        \"workspace.bronze_etl.ipca\",\n",
    "        \"workspace.bronze_etl.boi_gordo\",\n",
    "    ]:\n",
    "        return \"t.data = s.data AND t.valor = s.valor\"\n",
    "\n",
    "    return (\n",
    "        \"t.data = s.data \"\n",
    "        \"AND t.ipca = s.ipca \"\n",
    "        \"AND t.boi_gordo = s.boi_gordo\"\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_delta_table(df_join: DataFrame, tabela_destino: str) -> None:\n",
    "    \"\"\"\n",
    "    Realiza MERGE (upsert) de um DataFrame em uma tabela Delta Lake.\n",
    "\n",
    "    Regras de chaves:\n",
    "    -----------------\n",
    "    - Para 'workspace.bronze_etl.ipca' ou 'workspace.bronze_etl.boi_gordo': usa as colunas 'data', 'valor'\n",
    "    - Para demais tabelas: usa as colunas 'data', 'ipca', 'boi_gordo'\n",
    "    \"\"\"\n",
    "\n",
    "    if df_join is None or df_join.limit(1).count() == 0:\n",
    "        print(\"‚ö†Ô∏è Nenhum dado para atualizar.\")\n",
    "        return\n",
    "\n",
    "    total = df_join.count()\n",
    "    print(f\"‚úÖ Total de registros carregados: {total}\")\n",
    "\n",
    "    if spark.catalog.tableExists(tabela_destino):\n",
    "        print(f\"üì¶ Tabela {tabela_destino} j√° existe ‚Äî atualizando dados...\")\n",
    "\n",
    "        delta_table = DeltaTable.forName(spark, tabela_destino)\n",
    "\n",
    "        condicao_merge = get_merge_condition(tabela_destino)\n",
    "        print(f\"üîë Condi√ß√£o de merge usada: {condicao_merge}\")\n",
    "\n",
    "        (\n",
    "            delta_table.alias(\"t\")\n",
    "            .merge(\n",
    "                df_join.alias(\"s\"),\n",
    "                condicao_merge,\n",
    "            )\n",
    "            .whenMatchedUpdateAll()\n",
    "            .whenNotMatchedInsertAll()\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ MERGE conclu√≠do com sucesso em {tabela_destino}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"üÜï Tabela {tabela_destino} n√£o existe ‚Äî criando nova tabela...\")\n",
    "\n",
    "        (\n",
    "            df_join.write.format(\"delta\")\n",
    "            .partitionBy(\"data\")\n",
    "            .mode(\"append\")\n",
    "            .option(\"overwriteSchema\", \"true\")\n",
    "            .saveAsTable(tabela_destino)\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Tabela {tabela_destino} criada e dados inseridos com sucesso.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
